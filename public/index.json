[{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n`[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space $[0, 2^{32})$ into chunks of 65,536 ($2^{16}$) consecutive integers.\nContainer 0: $[0, 65536) \\rightarrow \\text{key} = 0$\nContainer 1: $[65536, 131072) \\rightarrow \\text{key} = 1$\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of $[0, 65536)$\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality $\\le 4096$) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality $\u0026gt; 4096$) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray $\\to$ Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer.\nBitmap $\\to$ Array: If elements are removed and cardinality drops, it converts back to save memory.\n$\\to$ RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations.\nHere is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n`[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality $\\le 4096$) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality $\u0026gt; 4096$) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray $\\to$ Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer.\nBitmap $\\to$ Array: If elements are removed and cardinality drops, it converts back to save memory.\n$\\to$ RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations.\nHere is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n`[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray $\\to$ Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer.\nBitmap $\\to$ Array: If elements are removed and cardinality drops, it converts back to save memory.\n$\\to$ RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations.\nHere is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n`[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer.\nBitmap → Array: If elements are removed and cardinality drops, it converts back to save memory.\n→ RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations.\nHere is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n`[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n`[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type **Optimized For ** Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n`[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy. I hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nOn a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how RoaringBitmap stores data.\nWhat is RoaringBitmap On a high level, RoaringBitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaringbitmap splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). RoaringBitmap dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps stores data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaring Bitmaps splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of RoaringBitmap. I first came across RoaringBitmap when I read about the Apache Iceberg v3 updates I found the general technique behind RoaringBitmap where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps stores data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaring Bitmaps splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaring Bitmaps splits every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switches between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\n##What is Roaring Bitmaps\nOn a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data\nRoaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data\nEach container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nNow suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"##Travel\nSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003cp\u003e##Travel\u003c/p\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is how basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data. Let\u0026rsquo;s pop the hood and see what\u0026rsquo;s actually happening.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps On a high level, Roaring Bitmaps divide your data (we will use 32 bit integers ) into Container (chunk) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divides the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divide the integer space[0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 1000, it will be stored in Container 0 because 100 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divide the integer space[0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 65,537, it will be stored in Container 1 because 65,537 falls in the range of [0, 65536)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divide the integer space[0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nFor example, if a integer\u0026rsquo;s high 16 bits equals 65,537, it will be stored in Container 1 because 65,537 falls in the range of [65536, 131072)\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divide the integer space[0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nExample: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers\nLow 16 bits: Stored in the corresponding Container.\nThe high 16 bits divide the integer space[0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\nExample: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 64bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space[0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 8 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space[0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space[0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nWe will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space[0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action We will use the Java implementation as a example\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create a array of bit of size 10, and each position (bit) corresponds to an subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you’d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating a array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you’d store [4, 7] The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space[0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation((https://github.com/lemire/RoaringBitmap/blob/b2580c61dea3e3f102a26b70ff3fa6065eabc448/RoaringBitmap/src/main/java/org/roaringbitmap/RoaringBitmap.java#L1061-L1071)) to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nI hope you find this article useful, If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction. The best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\n\u003cimg alt=\"Alt text\" loading=\"lazy\" src=\"/posts/roaring-bitmaps/hierarchy.jpg\"\u003e\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction. The best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\n\u003cimg alt=\"Alt text\" loading=\"lazy\" src=\"sea2nyc.jpg\"\u003e\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction. The best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\n\u003cimg alt=\"Alt text\" loading=\"lazy\" src=\"sea2nyc.jpg\"\u003e\n\u003cimg alt=\"Alt text\" loading=\"lazy\" src=\"caphil.jpg\"\u003e\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction. The best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\n\u003cimg alt=\"Alt text\" loading=\"lazy\" src=\"/posts/roaring-bitmaps/sea2nyc.png\"\u003e\n\u003cimg alt=\"Alt text\" loading=\"lazy\" src=\"caphil.jpg\"\u003e\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction. The best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\n\u003cimg alt=\"Alt text\" loading=\"lazy\" src=\"/posts/roaring-bitmaps/sea2nyc.png\"\u003e\n\u003cimg alt=\"Alt text\" loading=\"lazy\" src=\"/posts/roaring-bitmaps/caphil.png\"\u003e\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; \u0026lt;img src=\u0026quot;sea2nyc.png\u0026quot; alt=\u0026quot;Seattle to NYC\u0026quot; style=\u0026quot;max-width: 400px; width: 100%; height: auto;\u0026quot;\u0026gt; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; \u0026lt;img src=\u0026quot;hierarchy.jpg\u0026quot; alt=\u0026quot;Seattle to NYC\u0026quot; style=\u0026quot;max-width: 400px; width: 100%; height: auto;\u0026quot;\u0026gt; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\n\u0026lt;img src=\u0026quot;hierarchy.jpg\u0026quot; alt=\u0026quot; \u0026lt;img src=\u0026quot;hierarchy.jpg\u0026quot; alt=\u0026quot;Seattle to NYC\u0026quot; style=\u0026quot;max-width: 400px; width: 100%; height: \u0026quot; style=\u0026ldquo;max-width: 400px; width: 100%; height: auto;\u0026quot;\u0026gt;\nExample: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0\nContainer 1: [65536, 131072) → key = 1\n\u0026hellip;\n\u0026lt;img src=\u0026quot;hierarchy.jpg\u0026quot; alt=\u0026quot; \u0026lt;img src=\u0026quot;hierarchy.jpg\u0026quot; alt=\u0026quot;Seattle to NYC\u0026quot; style=\u0026quot;max-width: 400px; width: 100%; height: \u0026quot; style=\u0026ldquo;max-width: 400px; width: 100%; height: auto;\u0026quot;\u0026gt;\nExample: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; \u0026lt;img src=\u0026ldquo;hierarchy.jpg\u0026rdquo; alt=\u0026quot; \u0026lt;img src=\u0026ldquo;hierarchy.jpg\u0026rdquo; alt=\u0026ldquo;Seattle to NYC\u0026rdquo; style=\u0026ldquo;max-width: 400px; width: 100%; height:\n\u0026quot; style=\u0026ldquo;max-width: 400px; width: 100%; height: auto;\u0026quot;\u0026gt;\nExample: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; \u0026lt;img src=\u0026ldquo;hierarchy.jpg\u0026rdquo; alt=\u0026quot; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"},{"content":"Travel Suppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\nThe best way to get somewhere depends on the distance you\u0026rsquo;re traveling. Nobody uses the same transportation method for every trip. You look at each leg of your journey and pick the method that makes sense for that particular stretch.\nBitmap Now suppose you are a newsletter writer with 10 subscribers, and you want to write a program to keep track of how many of those subscribers are paid subscriber. One way to do it is by using a bitmap/ bitset, where you create an array of bits of size 10, and each position (bit) corresponds to a subscriber, and the bit is 1 if the subscriber is a paid subscriber and 0 if not. For example, label your subscribers from 0 to 9. If subscribers #1, #4, #6 and #7 are paid, you\u0026rsquo;d set those bit positions to 1 and leave the rest 0:\n[0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\nAnother way to do it is by creating an array of only paid subscribers, where the array stores the IDs of subscribers who are paid. For example, if subscribers #4, and #7 are paid, you\u0026rsquo;d store [4, 7]. The upside is that when only a small fraction of subscribers are paid, this representation is more space-efficient since you only store the paid ones, not 10 slots. The downside is that checking whether subscriber #5 is paid means searching the array (unless you keep it sorted and use binary search).\nNow you become a very successful writer with 1 billion subscribers and almost all of your old subscribers are paid subscribers.\nThe bitmap and the array approach would require 1 billion bits (about 125 MB) and around 1 billion INT (about 4 GB for 32bit INT) - manageable, but large. The sparse array approach would be terrible here because if 999 million out of 1 billion subscribers are paid, you\u0026rsquo;d need to store 999 million IDs! This is where Run-Length Encoding (RLE) shines. Instead of storing each bit individually, RLE compresses sequences by storing the length of consecutive runs of the same value. For example, if you have this bitmap:\n[1, 1, 1, 1, 1, 0, 1, 1, 1, 1] RLE would encode it as:\n[(1, 5), (0, 1), (1, 4)]\nwhich means: \u0026ldquo;five 1s, then one 0, then four 1s\u0026rdquo;\nWith 1 billion subscribers where almost everyone is paid, you might have:\n1 2 [1, 1, 1, ..., 1, 0, 1, 1, ..., 1, 0, 0, 1, 1, ..., 1] └─ 500M 1s ─┘ └─ 499M 1s ─┘ └─ rest ─┘ RLE could compress this to just a few entries:\n1 [(1, 500000000), (0, 1), (1, 499000000), (0, 2), (1, 999997)] Instead of storing 1 billion bits, you only store a handful of (value, length) pairs! This is extremely space-efficient when you have long runs of the same value\nSo far so good, but real life is messier than this.\nSuppose you have 1 billion subscribers but they signed up over time. Your first 100 million subscribers are superfans - almost all of them are paid (dense data, RLE is perfect). Then you went viral on Twitter and got 400 million drive-by subscribers, and only 1% of them converted to paid (super sparse data, array is perfect). Then your most recent 500 million subscribers have about 50% conversion (medium density, bitmap is perfect).\nIf you use just RLE for everything, you\u0026rsquo;re compressing \u0026ldquo;1, 0, 1, 0, 1, 0\u0026hellip;\u0026rdquo; in that middle chunk, which is terrible - RLE loves long runs, not alternating bits. If you use just arrays for everything, you\u0026rsquo;re storing 549 million IDs when you could\u0026rsquo;ve compressed most of them. If you use just bitmaps for everything, you\u0026rsquo;re using 125 MB when you could do much better.\nSimilar to our traveling example, the best way to store your data depends on the density of your subscribers. Nobody uses the same storage method for every chunk of data. You look at each segment of your subscriber base and pick the method that makes sense for that particular chunk.\nWell this is basically how Roaring Bitmaps store data.\nWhat is Roaring Bitmaps Roaring Bitmaps use a two-level system - think of it like a filing cabinet.\nOn a high level, Roaring Bitmaps divide your data (we\u0026rsquo;ll use 32-bit integers) into Containers (chunks) and then look at each container and update it to the most appropriate storage option as data gets updated.\nLevel 1: The \u0026ldquo;Directory\u0026rdquo; / How does it divide data Roaring Bitmaps split every 32-bit integer into two 16-bit parts:\n1 2 3 4 32-bit integer: [High 16 bits] [Low 16 bits] ↓ ↓ \u0026#34;Key\u0026#34; Stored in (to index Containers) Container High 16 bits: Stored as a key to index Containers Low 16 bits: Stored in the corresponding Container. The high 16 bits divide the integer space [0, 2^32) into chunks of 65,536 (2^16) consecutive integers.\nContainer 0: [0, 65536) → key = 0 Container 1: [65536, 131072) → key = 1 \u0026hellip; Example: Let\u0026rsquo;s say you want to store the integer 70,000.\nIn binary: 70,000 = 0000 0000 0000 0001 0001 0001 0111 0000 High 16 bits: 0000 0000 0000 0001 = 1 → This is the container key Low 16 bits: 0001 0001 0111 0000 = 4,464 → This is what gets stored So the integer 70,000 gets routed to Container 1 (because its high bits equal 1), and the value 4,464 is stored inside that container.\nLevel 2: The \u0026ldquo;Data Storage\u0026rdquo; / how does it store data Each container stores up to 65,536 values (the low 16 bits). Roaring Bitmaps dynamically switch between three container types based on data density to optimize memory.\nContainer Type Optimized For Threshold / Logic ArrayContainer Sparse Data\n(Cardinality ≤ 4096) Uses binary search for lookups. Extremely compact for few elements (e.g., 4 items = 8 bytes). BitmapContainer Dense Data\n(Cardinality \u0026gt; 4096) Fixed size of 8KB. Supports fast bitwise operations (AND/OR/XOR). RunContainer Sequential Data\n(Long runs of numbers) Run-Length Encoded (RLE). Example: {10, 11, 12, 13} becomes (10, 3). Created only via runOptimize(). How to add a value When you add a value, the system routes the data to the correct container or creates a new one.\nLet\u0026rsquo;s look at the official Java implementation to see this routing logic in action\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(final int x) { final short hb = Util.highbits(x); // 1. Extract high 16 bits final int i = highLowContainer.getIndex(hb); // 2. Binary search for key if (i \u0026gt;= 0) { // 3. Container exists - add low bits to it highLowContainer.setContainerAtIndex(i, highLowContainer.getContainerAtIndex(i).add(Util.lowbits(x))); //3.5 Will auto convert to a different container if threshold is met } else { // 4. No container - create new ArrayContainer final ArrayContainer newac = new ArrayContainer(); highLowContainer.insertNewKeyValueAt(-i - 1, hb, newac.add(Util.lowbits(x))); } } Auto-Conversion Logic:\nArray → Bitmap: If an ArrayContainer exceeds 4096 elements, it converts to a BitmapContainer. Bitmap → Array: If elements are removed and cardinality drops, it converts back to save memory. → RunContainer: Only occurs if explicitly requested via runOptimize() or during specific range operations. Here is the Java example of the Array to Bitmap conversion\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Override public Container add(int begin, int end) { ... if (newcardinality \u0026gt; DEFAULT_MAX_SIZE) { BitmapContainer a = this.toBitmapContainer(); return a.iadd(begin, end); } ... @Override public BitmapContainer toBitmapContainer() { BitmapContainer bc = new BitmapContainer(); bc.loadData(this); return bc; } There are other operations (set operation/ iteration/ aggregation) and other optimization (lazy operation /hybrid binary search/ SIMD) that I am not going to discuss here.\nConclusion In this blog we discussed the basics of Roaring Bitmaps. I first came across Roaring Bitmaps when I read about the Apache Iceberg v3 updates I found the general technique behind Roaring Bitmaps where you\nPartition by local homogeneity Apply best-fit technique per partition Maintain composability (operate on parts independently) to be really useful. This allows you to avoid worst-case performance and exploit local specialization for speed/space/accuracy.\nJust as you wouldn\u0026rsquo;t take a plane to the grocery store, you shouldn\u0026rsquo;t use a single data structure for every dataset. Partitioning your data allows you to walk when it\u0026rsquo;s close and fly when it\u0026rsquo;s far, giving you the best of both worlds. If you are interested in learning more, checkout https://roaringbitmap.org/\n","permalink":"http://localhost:1313/posts/roaring-bitmaps/","summary":"\u003ch2 id=\"travel\"\u003eTravel\u003c/h2\u003e\n\u003cp\u003eSuppose you want to travel from Seattle to New York City. You would (obviously) fly, because walking across the country would be insane. But if you want to go from your apartment in Capitol Hill to Pike Place Market in downtown, you\u0026rsquo;d probably take a bus and then walk a bit, because calling an Uber to the airport to catch a cross-country flight to go two miles would be, well, equally insane but in the opposite direction.\u003c/p\u003e","title":"Roaring Bitmaps"},{"content":"huh ?\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003ehuh ?\u003c/p\u003e","title":"About"}]